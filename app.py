import streamlit as st
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.markdown("## InternLM LLM")
    st.markdown("[GitHub](https://github.com/ljn12yyds/zhangsan_say_law)")
    # åˆ›å»ºä¸€ä¸ªæ»‘å—ï¼Œç”¨äºé€‰æ‹©æœ€å¤§é•¿åº¦ï¼ŒèŒƒå›´åœ¨0åˆ°1024ä¹‹é—´ï¼Œé»˜è®¤å€¼ä¸º512
    max_length = st.slider("Max Length", 0, 1024, 512, step=1)
    system_prompt = st.text_input("System Prompt", "ä½ æ˜¯ä¸€ä¸ªç”±ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤æä¾›æ”¯æŒå¼€å‘çš„æ³•å¾‹å¤§æ¨¡å‹ã€‚ç°åœ¨ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„æ³•å¾‹å­¦ä¸“å®¶ï¼Œåå«å¼ ä¸‰ã€‚æˆ‘æœ‰ä¸€äº›å…³äºæ³•å¾‹æ–¹é¢çš„é—®é¢˜ï¼Œè¯·ä½ ç”¨ä¸“ä¸šçš„çŸ¥è¯†å¼•ç”¨ç›¸å…³çš„æ³•å¾‹æ³•è§„å¸®æˆ‘è§£å†³")

# åˆ›å»ºä¸€ä¸ªæ ‡é¢˜å’Œä¸€ä¸ªå‰¯æ ‡é¢˜
st.title("ğŸ’¬ InternLM2-Chat-7B å¼ ä¸‰æ™®æ³•")
st.caption("ğŸš€ A streamlit chatbot powered by InternLM2 QLora")

# å®šä¹‰æ¨¡å‹è·¯å¾„
model_id = 'ljnyyds/zhangsan_say_law'

# è·å–æ¨¡å‹å’Œåˆ†è¯å™¨
@st.cache_resource
def get_model():
    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, torch_dtype=torch.bfloat16).cuda()
    model.eval()
    return tokenizer, model

tokenizer, model = get_model()

# åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for i, (user_message, assistant_message) in enumerate(st.session_state.messages):
    st.text_area(f"User message {i}", value=user_message, height=75)
    st.text_area(f"Assistant message {i}", value=assistant_message, height=75)

# è·å–ç”¨æˆ·è¾“å…¥
prompt = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š", key="new_message")

# å¦‚æœç”¨æˆ·è¾“å…¥äº†å†…å®¹ï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹æ“ä½œ
if prompt:
    # æ„å»ºè¾“å…¥
    input_ids = tokenizer.encode(prompt, return_tensors='pt').cuda()
    
    # ç”Ÿæˆæ¨¡å‹å“åº”
    with torch.no_grad():
        output = model.generate(input_ids, max_length=max_length)
    
    # è§£ç æ¨¡å‹å“åº”
    response = tokenizer.decode(output[0], skip_special_tokens=True)
    
    # å°†ç”¨æˆ·è¾“å…¥å’Œæ¨¡å‹å“åº”æ·»åŠ åˆ° session_state ä¸­çš„ messages åˆ—è¡¨ä¸­
    st.session_state.messages.append((prompt, response))
    
    # æ¸…ç©ºè¾“å…¥æ¡†
    st.session_state["new_message"] = ""
